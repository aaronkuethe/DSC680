{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSC 550\n",
    "# Week 2\n",
    "# Assignment 2.2\n",
    "# Aaron Kuethe\n",
    "\n",
    "\n",
    "# Install Packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import string\n",
    "import unicodedata\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>You are right Mr. President.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>You have given no input apart from saying I am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>I get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>I am far from an expert on TPP and I would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949995</td>\n",
       "      <td>0</td>\n",
       "      <td>I genuinely can't understand how anyone can su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949996</td>\n",
       "      <td>0</td>\n",
       "      <td>As a reminder, this subreddit [is for civil di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949997</td>\n",
       "      <td>0</td>\n",
       "      <td>K. Don't explain why or anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949998</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949999</td>\n",
       "      <td>0</td>\n",
       "      <td>Ya, sociopaths are known for celebrating their...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  Well it's great that he did something about th...\n",
       "1         0                       You are right Mr. President.\n",
       "2         0  You have given no input apart from saying I am...\n",
       "3         0  I get the frustration but the reason they want...\n",
       "4         0  I am far from an expert on TPP and I would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  I genuinely can't understand how anyone can su...\n",
       "949996    0  As a reminder, this subreddit [is for civil di...\n",
       "949997    0                  K. Don't explain why or anything.\n",
       "949998    0                                          [deleted]\n",
       "949999    0  Ya, sociopaths are known for celebrating their...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. You can find the dataset controversial-comments.jsonl for this exercise in the Weekly Resources: Week 2 Data Files.\n",
    "\n",
    "# Pre-processing Text: For this part, you will start by reading the controversial-comments.jsonl file into a DataFrame.\n",
    "\n",
    "data_df = pd.read_json('controversial-comments.jsonl', lines=True)\n",
    "data_df\n",
    "\n",
    "# JSON file has been loaded into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well it's great that he did something about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr. president.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949995</td>\n",
       "      <td>0</td>\n",
       "      <td>i genuinely can't understand how anyone can su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949996</td>\n",
       "      <td>0</td>\n",
       "      <td>as a reminder, this subreddit [is for civil di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949997</td>\n",
       "      <td>0</td>\n",
       "      <td>k. don't explain why or anything.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949998</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949999</td>\n",
       "      <td>0</td>\n",
       "      <td>ya, sociopaths are known for celebrating their...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  well it's great that he did something about th...\n",
       "1         0                       you are right mr. president.\n",
       "2         0  you have given no input apart from saying i am...\n",
       "3         0  i get the frustration but the reason they want...\n",
       "4         0  i am far from an expert on tpp and i would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  i genuinely can't understand how anyone can su...\n",
       "949996    0  as a reminder, this subreddit [is for civil di...\n",
       "949997    0                  k. don't explain why or anything.\n",
       "949998    0                                          [deleted]\n",
       "949999    0  ya, sociopaths are known for celebrating their...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.A.\n",
    "\n",
    "# Then,\n",
    "\n",
    "# A. Convert all text to lowercase letters.\n",
    "\n",
    "data_df['txt'] = data_df['txt'].str.lower()\n",
    "data_df\n",
    "\n",
    "# Text column is now all lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949995</td>\n",
       "      <td>0</td>\n",
       "      <td>i genuinely cant understand how anyone can sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949996</td>\n",
       "      <td>0</td>\n",
       "      <td>as a reminder this subreddit is for civil disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949997</td>\n",
       "      <td>0</td>\n",
       "      <td>k dont explain why or anything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949998</td>\n",
       "      <td>0</td>\n",
       "      <td>deleted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949999</td>\n",
       "      <td>0</td>\n",
       "      <td>ya sociopaths are known for celebrating their ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt\n",
       "0         0  well its great that he did something about tho...\n",
       "1         0                         you are right mr president\n",
       "2         0  you have given no input apart from saying i am...\n",
       "3         0  i get the frustration but the reason they want...\n",
       "4         0  i am far from an expert on tpp and i would ten...\n",
       "...     ...                                                ...\n",
       "949995    0  i genuinely cant understand how anyone can sup...\n",
       "949996    0  as a reminder this subreddit is for civil disc...\n",
       "949997    0                     k dont explain why or anything\n",
       "949998    0                                            deleted\n",
       "949999    0  ya sociopaths are known for celebrating their ...\n",
       "\n",
       "[950000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.B.\n",
    "\n",
    "# B. Remove all punctuation from the text.\n",
    "\n",
    "string.punctuation\n",
    "\n",
    "data_df['txt'] = data_df['txt'].str.replace(r'[^\\w\\s]+','')\n",
    "data_df\n",
    "\n",
    "# Text column now has no punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aaronk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aaronk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>[well, great, something, beliefs, office, doub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>[right, mr, president]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>[given, input, apart, saying, wrong, argument,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>[get, frustration, reason, want, way, foundati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>[far, expert, tpp, would, tend, agree, lot, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949995</td>\n",
       "      <td>0</td>\n",
       "      <td>i genuinely cant understand how anyone can sup...</td>\n",
       "      <td>[genuinely, cant, understand, anyone, support,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949996</td>\n",
       "      <td>0</td>\n",
       "      <td>as a reminder this subreddit is for civil disc...</td>\n",
       "      <td>[reminder, subreddit, civil, discussionhttpsww...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949997</td>\n",
       "      <td>0</td>\n",
       "      <td>k dont explain why or anything</td>\n",
       "      <td>[k, dont, explain, anything]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949998</td>\n",
       "      <td>0</td>\n",
       "      <td>deleted</td>\n",
       "      <td>[deleted]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949999</td>\n",
       "      <td>0</td>\n",
       "      <td>ya sociopaths are known for celebrating their ...</td>\n",
       "      <td>[ya, sociopaths, known, celebrating, positive,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt  \\\n",
       "0         0  well its great that he did something about tho...   \n",
       "1         0                         you are right mr president   \n",
       "2         0  you have given no input apart from saying i am...   \n",
       "3         0  i get the frustration but the reason they want...   \n",
       "4         0  i am far from an expert on tpp and i would ten...   \n",
       "...     ...                                                ...   \n",
       "949995    0  i genuinely cant understand how anyone can sup...   \n",
       "949996    0  as a reminder this subreddit is for civil disc...   \n",
       "949997    0                     k dont explain why or anything   \n",
       "949998    0                                            deleted   \n",
       "949999    0  ya sociopaths are known for celebrating their ...   \n",
       "\n",
       "                                                    token  \n",
       "0       [well, great, something, beliefs, office, doub...  \n",
       "1                                  [right, mr, president]  \n",
       "2       [given, input, apart, saying, wrong, argument,...  \n",
       "3       [get, frustration, reason, want, way, foundati...  \n",
       "4       [far, expert, tpp, would, tend, agree, lot, pr...  \n",
       "...                                                   ...  \n",
       "949995  [genuinely, cant, understand, anyone, support,...  \n",
       "949996  [reminder, subreddit, civil, discussionhttpsww...  \n",
       "949997                       [k, dont, explain, anything]  \n",
       "949998                                          [deleted]  \n",
       "949999  [ya, sociopaths, known, celebrating, positive,...  \n",
       "\n",
       "[950000 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.C.\n",
    "\n",
    "# C. Remove stop words.\n",
    "\n",
    "# Importing list of stopwords to exclude\n",
    "from nltk.corpus import stopwords\n",
    "    \n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)\n",
    "\n",
    "# Creating tokenized list of words, therefore can remove individual words from the sentences of text.\n",
    "from nltk.tokenize import word_tokenize\n",
    "data_df['token'] = data_df['txt'].apply(word_tokenize)\n",
    "\n",
    " \n",
    "# Removing stop words\n",
    "data_df['token']= data_df['token'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "data_df\n",
    "\n",
    "# Added in new 'token' column to see that words were in fact removed from the 'txt' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>con</th>\n",
       "      <th>txt</th>\n",
       "      <th>token</th>\n",
       "      <th>stem_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>well its great that he did something about tho...</td>\n",
       "      <td>[well, great, something, beliefs, office, doub...</td>\n",
       "      <td>[well, great, someth, belief, offic, doubt, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>you are right mr president</td>\n",
       "      <td>[right, mr, president]</td>\n",
       "      <td>[right, mr, presid]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>you have given no input apart from saying i am...</td>\n",
       "      <td>[given, input, apart, saying, wrong, argument,...</td>\n",
       "      <td>[given, input, apart, say, wrong, argument, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>i get the frustration but the reason they want...</td>\n",
       "      <td>[get, frustration, reason, want, way, foundati...</td>\n",
       "      <td>[get, frustrat, reason, want, way, foundat, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>i am far from an expert on tpp and i would ten...</td>\n",
       "      <td>[far, expert, tpp, would, tend, agree, lot, pr...</td>\n",
       "      <td>[far, expert, tpp, would, tend, agre, lot, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949995</td>\n",
       "      <td>0</td>\n",
       "      <td>i genuinely cant understand how anyone can sup...</td>\n",
       "      <td>[genuinely, cant, understand, anyone, support,...</td>\n",
       "      <td>[genuin, cant, understand, anyon, support, poi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949996</td>\n",
       "      <td>0</td>\n",
       "      <td>as a reminder this subreddit is for civil disc...</td>\n",
       "      <td>[reminder, subreddit, civil, discussionhttpsww...</td>\n",
       "      <td>[remind, subreddit, civil, discussionhttpswwwr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949997</td>\n",
       "      <td>0</td>\n",
       "      <td>k dont explain why or anything</td>\n",
       "      <td>[k, dont, explain, anything]</td>\n",
       "      <td>[k, dont, explain, anyth]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949998</td>\n",
       "      <td>0</td>\n",
       "      <td>deleted</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>[delet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>949999</td>\n",
       "      <td>0</td>\n",
       "      <td>ya sociopaths are known for celebrating their ...</td>\n",
       "      <td>[ya, sociopaths, known, celebrating, positive,...</td>\n",
       "      <td>[ya, sociopath, known, celebr, posit, feel, fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>950000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        con                                                txt  \\\n",
       "0         0  well its great that he did something about tho...   \n",
       "1         0                         you are right mr president   \n",
       "2         0  you have given no input apart from saying i am...   \n",
       "3         0  i get the frustration but the reason they want...   \n",
       "4         0  i am far from an expert on tpp and i would ten...   \n",
       "...     ...                                                ...   \n",
       "949995    0  i genuinely cant understand how anyone can sup...   \n",
       "949996    0  as a reminder this subreddit is for civil disc...   \n",
       "949997    0                     k dont explain why or anything   \n",
       "949998    0                                            deleted   \n",
       "949999    0  ya sociopaths are known for celebrating their ...   \n",
       "\n",
       "                                                    token  \\\n",
       "0       [well, great, something, beliefs, office, doub...   \n",
       "1                                  [right, mr, president]   \n",
       "2       [given, input, apart, saying, wrong, argument,...   \n",
       "3       [get, frustration, reason, want, way, foundati...   \n",
       "4       [far, expert, tpp, would, tend, agree, lot, pr...   \n",
       "...                                                   ...   \n",
       "949995  [genuinely, cant, understand, anyone, support,...   \n",
       "949996  [reminder, subreddit, civil, discussionhttpsww...   \n",
       "949997                       [k, dont, explain, anything]   \n",
       "949998                                          [deleted]   \n",
       "949999  [ya, sociopaths, known, celebrating, positive,...   \n",
       "\n",
       "                                               stem_token  \n",
       "0       [well, great, someth, belief, offic, doubt, tr...  \n",
       "1                                     [right, mr, presid]  \n",
       "2       [given, input, apart, say, wrong, argument, cl...  \n",
       "3       [get, frustrat, reason, want, way, foundat, co...  \n",
       "4       [far, expert, tpp, would, tend, agre, lot, pro...  \n",
       "...                                                   ...  \n",
       "949995  [genuin, cant, understand, anyon, support, poi...  \n",
       "949996  [remind, subreddit, civil, discussionhttpswwwr...  \n",
       "949997                          [k, dont, explain, anyth]  \n",
       "949998                                            [delet]  \n",
       "949999  [ya, sociopath, known, celebr, posit, feel, fu...  \n",
       "\n",
       "[950000 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.D.\n",
    "\n",
    "# D. Apply NLTK’s PorterStemmer.\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "data_df['stem_token'] = data_df['token'].apply(lambda x: [ps.stem(y) for y in x])\n",
    "\n",
    "# Added new column 'stem_token' to see if the words were in fact stemmed.\n",
    "\n",
    "# Displaying new dataframe to check if the output is as expected.\n",
    "\n",
    "data_df\n",
    "\n",
    "# Words were stemmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accus</th>\n",
       "      <th>action</th>\n",
       "      <th>agre</th>\n",
       "      <th>aideassist</th>\n",
       "      <th>alreadi</th>\n",
       "      <th>also</th>\n",
       "      <th>alway</th>\n",
       "      <th>american</th>\n",
       "      <th>anyth</th>\n",
       "      <th>appear</th>\n",
       "      <th>...</th>\n",
       "      <th>use</th>\n",
       "      <th>user</th>\n",
       "      <th>vote</th>\n",
       "      <th>whether</th>\n",
       "      <th>white</th>\n",
       "      <th>will</th>\n",
       "      <th>within</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>would</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accus  action  agre  aideassist  alreadi  also  alway  american  anyth  \\\n",
       "0      0       0     0           0        1     0      0         0      0   \n",
       "1      0       0     0           0        0     0      0         0      0   \n",
       "2      0       0     0           0        0     0      1         0      0   \n",
       "3      1       1     1           0        0     0      0         0      1   \n",
       "4      0       0     0           0        0     1      0         0      0   \n",
       "5      0       0     0           1        0     1      0         0      0   \n",
       "6      0       0     0           0        0     0      0         0      0   \n",
       "7      0       0     0           0        0     0      0         0      0   \n",
       "8      0       0     0           0        0     0      0         1      0   \n",
       "9      0       0     0           0        1     0      0         0      0   \n",
       "\n",
       "   appear  ...  use  user  vote  whether  white  will  within  wont  work  \\\n",
       "0       1  ...    0     0     0        0      0     0       0     0     1   \n",
       "1       0  ...    0     0     0        0      0     0       0     0     0   \n",
       "2       0  ...    0     0     0        0      0     0       0     0     0   \n",
       "3       0  ...    1     5     0        2      0     1       0     0     0   \n",
       "4       0  ...    0     0     0        0      0     0       0     0     0   \n",
       "5       0  ...    0     0     0        0      0     0       0     0     0   \n",
       "6       0  ...    0     0     1        0      0     0       0     0     0   \n",
       "7       0  ...    0     0     0        0      0     0       0     0     0   \n",
       "8       0  ...    1     0     0        0      1     0       0     1     1   \n",
       "9       0  ...    0     0     0        0      0     0       1     0     0   \n",
       "\n",
       "   would  \n",
       "0      1  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      1  \n",
       "5      0  \n",
       "6      0  \n",
       "7      0  \n",
       "8      0  \n",
       "9      0  \n",
       "\n",
       "[10 rows x 157 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Now that the data is pre-processed, you will apply three different techniques to get it into a usable form for \n",
    "# model-building. Apply each of the following steps (individually) to the pre-processed data.\n",
    "\n",
    "# 2.A. Convert each text entry into a word-count vector (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook).\n",
    "\n",
    "data_df['stem_token'] = data_df['stem_token'].astype(str)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "\n",
    "# Creating a sample to work with due to memory issues. Also picked a smaller sample size so that I could see numbers besides 0.\n",
    "# I could get roughly 30,000 rows at most, but all the values were 0 and several of the words looked to be Russian. This\n",
    "# smaller sample looks more visually appealing to me.\n",
    "\n",
    "data_dftest = data_df.sample(frac = .00001)\n",
    "\n",
    "# Creating bag of words and array\n",
    "bow = count_vect.fit_transform(np.array(data_dftest['stem_token'].values.astype('U')))\n",
    "array = bow.toarray()\n",
    "\n",
    "# Getting words to be column names\n",
    "df = pd.DataFrame(array, columns= count_vect.get_feature_names())\n",
    "df\n",
    "\n",
    "# Part 2.A Continued\n",
    "# Give an example where each would be useful.\n",
    "# This would be a great exercise for companies to use when trying to get customer feedback and sentiment about a service. An\n",
    "# example would be Hy-Vee grocery store chain receving feedback about their online grocery delivery serviec. They could see how\n",
    "# many times negative words such as 'bad', 'worse', 'poor', etc show up. They could also see how many times they receive good\n",
    "# feedback as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\aaronk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('accus', 'JJ'),\n",
       " ('action', 'NN'),\n",
       " ('agre', 'IN'),\n",
       " ('aideassist', 'NN'),\n",
       " ('alreadi', 'NN'),\n",
       " ('also', 'RB'),\n",
       " ('alway', 'RB'),\n",
       " ('american', 'JJ'),\n",
       " ('anyth', 'NN'),\n",
       " ('appear', 'VBP'),\n",
       " ('around', 'IN'),\n",
       " ('articl', 'JJ'),\n",
       " ('attack', 'NN'),\n",
       " ('attorney', 'NN'),\n",
       " ('automat', 'NN'),\n",
       " ('bait', 'NN'),\n",
       " ('ban', 'NN'),\n",
       " ('baron', 'NN'),\n",
       " ('beck', 'NN'),\n",
       " ('believ', 'NN'),\n",
       " ('bot', 'NN'),\n",
       " ('call', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('civil', 'JJ'),\n",
       " ('clever', 'NN'),\n",
       " ('come', 'VBP'),\n",
       " ('comment', 'NN'),\n",
       " ('concern', 'NN'),\n",
       " ('conduct', 'NN'),\n",
       " ('contact', 'NN'),\n",
       " ('day', 'NN'),\n",
       " ('deal', 'VB'),\n",
       " ('death', 'NN'),\n",
       " ('dem', 'NN'),\n",
       " ('disagre', 'VBP'),\n",
       " ('discussionhttpswwwredditcomrpoliticswikirulesandregswiki_please_be_civil',\n",
       "  'JJ'),\n",
       " ('doesnt', 'NN'),\n",
       " ('dont', 'NN'),\n",
       " ('downvot', 'NN'),\n",
       " ('editor', 'NN'),\n",
       " ('els', 'JJ'),\n",
       " ('escal', 'JJ'),\n",
       " ('etc', 'NN'),\n",
       " ('explicit', 'NN'),\n",
       " ('far', 'RB'),\n",
       " ('father', 'RB'),\n",
       " ('feel', 'VB'),\n",
       " ('femin', 'JJ'),\n",
       " ('fire', 'NN'),\n",
       " ('follow', 'VBP'),\n",
       " ('free', 'JJ'),\n",
       " ('fuck', 'NN'),\n",
       " ('gener', 'NN'),\n",
       " ('glenn', 'VBD'),\n",
       " ('good', 'JJ'),\n",
       " ('hate', 'NN'),\n",
       " ('head', 'NN'),\n",
       " ('held', 'VBD'),\n",
       " ('hi', 'RB'),\n",
       " ('hous', 'JJ'),\n",
       " ('household', 'NN'),\n",
       " ('howev', 'NN'),\n",
       " ('httpreddit5hw49m', 'NN'),\n",
       " ('idea', 'NN'),\n",
       " ('im', 'NN'),\n",
       " ('implicit', 'JJ'),\n",
       " ('incivil', 'JJ'),\n",
       " ('incredo22', 'NN'),\n",
       " ('jerk', 'NN'),\n",
       " ('lack', 'NN'),\n",
       " ('last', 'JJ'),\n",
       " ('like', 'IN'),\n",
       " ('make', 'VBP'),\n",
       " ('marti', 'NN'),\n",
       " ('may', 'MD'),\n",
       " ('men', 'NNS'),\n",
       " ('messag', 'VB'),\n",
       " ('mistak', 'NNS'),\n",
       " ('moder', 'VB'),\n",
       " ('moderatorshttpswwwredditcommessagecomposetorpoliticsampsubjectquest',\n",
       "  'JJS'),\n",
       " ('modmail', 'NN'),\n",
       " ('moron', 'NN'),\n",
       " ('opinion', 'NN'),\n",
       " ('origin', 'IN'),\n",
       " ('particip', 'FW'),\n",
       " ('patriarchi', 'FW'),\n",
       " ('peopl', 'FW'),\n",
       " ('perform', 'VB'),\n",
       " ('permittedhttpswwwredditcomrpoliticswikirulesandregswiki_no_personal_attack',\n",
       "  'NN'),\n",
       " ('person', 'NN'),\n",
       " ('pleas', 'JJ'),\n",
       " ('point', 'NN'),\n",
       " ('polit', 'NN'),\n",
       " ('politician', 'JJ'),\n",
       " ('portray', 'NN'),\n",
       " ('presid', 'NN'),\n",
       " ('proper', 'IN'),\n",
       " ('qualiti', 'JJ'),\n",
       " ('question', 'NN'),\n",
       " ('ran', 'VBD'),\n",
       " ('realli', 'JJ'),\n",
       " ('reason', 'NN'),\n",
       " ('regard', 'NN'),\n",
       " ('remind', 'NN'),\n",
       " ('remov', 'NN'),\n",
       " ('repli', 'JJ'),\n",
       " ('report', 'NN'),\n",
       " ('respond', 'NN'),\n",
       " ('result', 'NN'),\n",
       " ('right', 'JJ'),\n",
       " ('rpolit', 'NN'),\n",
       " ('rule', 'NN'),\n",
       " ('ruler', 'NNS'),\n",
       " ('say', 'VBP'),\n",
       " ('scenario', 'NN'),\n",
       " ('score', 'NN'),\n",
       " ('see', 'VBP'),\n",
       " ('seem', 'VBP'),\n",
       " ('send', 'VB'),\n",
       " ('shadi', 'NN'),\n",
       " ('shill', 'NN'),\n",
       " ('situat', 'VBZ'),\n",
       " ('soldier', 'JJR'),\n",
       " ('someon', 'NN'),\n",
       " ('sometim', 'NN'),\n",
       " ('speech', 'NN'),\n",
       " ('spotlight', 'VBD'),\n",
       " ('state', 'NN'),\n",
       " ('strategi', 'NN'),\n",
       " ('struggl', 'NN'),\n",
       " ('submiss', 'JJ'),\n",
       " ('submissionhttpswwwredditcomrpoliticscomments5i3jb2donald_trumps_campaign_paid_11_million_to_trump',\n",
       "  'NN'),\n",
       " ('submit', 'NN'),\n",
       " ('subreddit', 'NN'),\n",
       " ('subredditmessagecomposetorpolit', 'JJ'),\n",
       " ('term', 'NN'),\n",
       " ('thank', 'VBD'),\n",
       " ('theblaz', 'JJ'),\n",
       " ('think', 'VB'),\n",
       " ('three', 'CD'),\n",
       " ('time', 'NN'),\n",
       " ('tri', 'CC'),\n",
       " ('troll', 'NN'),\n",
       " ('uincredo22ampmessagei', 'JJ'),\n",
       " ('uncivil', 'JJ'),\n",
       " ('upvot', 'NN'),\n",
       " ('us', 'PRP'),\n",
       " ('use', 'VBP'),\n",
       " ('user', 'JJ'),\n",
       " ('vote', 'NN'),\n",
       " ('whether', 'IN'),\n",
       " ('white', 'JJ'),\n",
       " ('will', 'MD'),\n",
       " ('within', 'IN'),\n",
       " ('wont', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('would', 'MD')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. CONTINUED\n",
    "\n",
    "# 2.B. Convert each text entry into a part-of-speech tag vector (see section 6.7 in the Machine Learning with Python Cookbook).\n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# Creating part of speech tag for each word.\n",
    "tagged = nltk.pos_tag(df)\n",
    "\n",
    "# Displaying the words and part of speech tag.\n",
    "tagged\n",
    "\n",
    "# Part 2.B. Continued\n",
    "# Give an example where each would be useful.\n",
    "# This is useful to find the parts of speech of words or sentences. If we had a list of tweets and we wanted to see who the\n",
    "# they were about and what they were doing we could easily see which part of the tweets were tagged as nouns vs verbs, etc. We\n",
    "# could also be able to identify the tense, so if the tweeets were about a past event, a current event, or something that will\n",
    "# happen in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<157x157 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 157 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. CONTINUED\n",
    "\n",
    "# 2.C.Convert each entry into a term frequency-inverse document frequency (tfidf) vector (see section 6.9 in the Machine \n",
    "# Learning with Python Cookbook).\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "feature_matrix = tfidf.fit_transform(df)\n",
    "\n",
    "feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>accus</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>action</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>agre</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>aideassist</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>alreadi</td>\n",
       "      <td>2.299283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>will</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>within</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wont</td>\n",
       "      <td>2.704748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>work</td>\n",
       "      <td>2.299283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>would</td>\n",
       "      <td>2.299283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idf_weights\n",
       "accus          2.704748\n",
       "action         2.704748\n",
       "agre           2.704748\n",
       "aideassist     2.704748\n",
       "alreadi        2.299283\n",
       "...                 ...\n",
       "will           2.704748\n",
       "within         2.704748\n",
       "wont           2.704748\n",
       "work           2.299283\n",
       "would          2.299283\n",
       "\n",
       "[157 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating tdidf\n",
    "tfidf_transformer = TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "tfidf_transformer.fit(bow)\n",
    "\n",
    "# Creating weight of importance of each word\n",
    "df_idf = pd.DataFrame(tfidf_transformer.idf_, index=count_vect.get_feature_names(),columns=['idf_weights'])\n",
    "df_idf\n",
    "\n",
    "# Since I used a smaller sample set, the words might have a larger significance than if using a larger set with more words.\n",
    "\n",
    "# Part 2.C. Continued\n",
    "# Give an example where each would be useful.\n",
    "# This would be a useful exercise if you are wanting to look across multiple documents and determine how important a word is\n",
    "# to a given document. If you are looking for an article on the economy, there will be a score for the frequency of the word\n",
    "# \"economy\" and it might suggest that the article contains infromation about the economy. If you are looking for an article on\n",
    "# basketball, or specifically college over the NBA, words like \"college\" and \"basketball\" might have a higher value in a given\n",
    "# document. Essentially, this will help a reader find more important relevant documents without having to read a bunch of\n",
    "# different documents first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
